
# 2.11~2.13第二周 神经网络基础
[TOC]

### 2.11 向量化(Vectorization)
&emsp;　向量化是非常基础的去除代码中for循环的艺术，因为深度学习算法处理大数据集效果很棒，所以你的代码运行速度非常重要，而for循环非常耗费时间，所以运行向量化是一个关键的技巧。
* for循环方式计算$z = w^Tx + b$,其中W和X是R内的$n_x$维向量：
	&emsp;　Z=0
	&emsp;　for I in range(n-x)
	&emsp;&emsp;　　Z+=W[i]*X[i]
	&emsp;　Z+=b
	

* 向量化实现方式，直接用python自带语法计算$W^TX$：
	Z=np.dot(W,X)+b
	* 相同的两个矩阵相乘运算，向量化实现方式比for循环速度快约300倍

* CPU和GPU
&emsp;　大规模的深度学习会使用GPU或图像处理单元来实现，因为在CPU和GPU上，都有一种叫并行化的指令，也称SIMD指令。
&emsp;　像python里的numpy库内置方法就充分利用了并行化计算使计算效率大大提高。而在并行化计算方面GPU表现比CPU更出色，但CPU的并行化计算已满足入门学习需要。
<br>
### 2.12 更多的向量化例子（More Examples of Vectorization）
* np.dot(A,V)矩阵点乘
	如果要计算的矩阵不止1列，如两列A(i,j),然后与1列矩阵V(i)相乘，用for loop方式则需要循环套循环才能遍历A(i,j)

* np.exp(v) 矩阵元素指数化
	如果你已经有一个向量v，并且想要对向量v 的每个元素做指数操作等于e为底数，v为指数，得到向量u等于$e^{v_1},e^{v_2},e^{v_3},...e^{v_n}$

* np.log(v) 矩阵元素对数化
	把矩阵的元素变为对数，一般默认以2为底数，v为真数，新矩阵u=$\log{v_1},\log{v_2},...\log{v_n}$
	
* np.abss是计算数据的绝对值,np.maximum计算元素y中的最大值;2**v 代表获得元素y每个值得平方;1/v获取所有元素的倒数等等。
<br>

* **将np库的方法应用到逻辑回归梯度下降算法中**
	1.w是一个nx维\*1矩阵，dw即对矩阵内每个元素对J函数求导，所以也是一个矩阵nx维\*1的矩阵，所以初始化:
	$$dw = np.zeros((n_x,1))$$
	#zeros方法按行列数要求初始出一个全0矩阵
	2.原来的$dw_1 +=dz^{(i)}*x_1^{(i)} dw_2 +=dz^{(i)}*x_2^{(i)}$，向量化改为：
	$dw(i) += x^{(i)}dz^{(i)}$

<br>

### 2.13 向量化逻辑回归(Vectorizing Logistic Regression)
* z = w^Tx + b矩阵化
	* 回顾前向逻辑传播步骤：以第一个样本为例：
	&emsp;　$z^{(1)} = w^Tx^{(1)} + b$
	&emsp;　$a^{(1)}=\sigma(z^{(1)})=\frac{1}{1+e^{-z^{(1)}}}$
	&emsp;　如果有m个样本就有$z^{(m)}$,正常编程步骤就要用for循环遍历所有样本,但我们可以把每个z元素放在一个m\*1的Z矩阵中。
	&emsp;　我们之前把每个样本x放在X矩阵，z也一样可以这样操作，表达为：
	$$[z^{(1)},z^{(2)}..z^{(m)}]=W^TX+[bb...b]$$
	* [bb...b]也可以视为一个1\*m的行向量
	* 根据矩阵乘法，W矩阵的转置乘以X就是分别乘以X矩阵里的每个单列矩阵向量$x_1...x_m$；而一个单行向量$W^T$乘以一个单列向量$x_m$得出的是一个数值而非矩阵,此数值加上参数b，就成为单行矩阵Z里的一个元素:
		$$Z=[z^{(1)},z^{(2)}..z^{(m)}]=[W^Tx^{(1)}+b,...,W^Tx^{(m)}+b,]$$
		
<br>

* 预测结果函数$a=\sigma(z)$矩阵化
&emsp;　跟Z矩阵一样,$A=[a^{(1)},..,a^{(m)}]$,然后在编程里面我们可以自定义一个sigma函数，让这个函数对矩阵Z每个元素$z^m$进行$\frac{1}{1+e^{-z^{(m)}}}$运算，结果得出新元素$a^{(m)}$新矩阵A:
$$A=sigma(Z)=[a^{(1)},..,a^{(m)}]=[\frac{1}{1+e^{-z^{(1)}}},...,\frac{1}{1+e^{-z^{(m)}}}]$$
	
	
	


<!--stackedit_data:
eyJoaXN0b3J5IjpbNjM0ODQwNjYwXX0=
-->