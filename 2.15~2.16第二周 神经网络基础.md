
# 2.15~2.16第二周 神经网络基础
[TOC]

### 2.15 Python 中的广播机制（Broadcasting in Python）
![ea243103.png](:storage\964c5925-1e39-4450-8124-7afe77a826b0\ea243103.png)
&emsp; 用矩阵运算的方式计算不同食物中不同营养成分中的卡路里百分比。
* 求和矩阵cal=目标矩阵A.sum(axis=0)
	&emsp; 上式表示对矩阵A按列求和，axis 用来指明将要进行的运算是沿着哪个轴执行，在numpy中，0轴是垂直的，也就是列，而1 轴是水平的，也就是行。

* 和矩阵cal.reshape(1,4)
&emsp; 将矩阵cal重塑成1\*4矩阵，当我们写代码时不确定矩阵维度的时候，通常会对矩阵
进行重塑来确保得到我们想要的是列向量或行向量。
&emsp; 另外，重塑操作reshape是一个常量时间的操作，时间复杂度是O(1)，它的调用代价极低。

* numpy的广播机制
	* &emsp; 当一个1\*4的列向量与一个常数做加法时，实际上会将常数扩展为一个1\*4的列向量，然后两者做逐元素加法。 **注意：** 这种广播机制只对单行向量和单列向量可以使用。
	* &emsp; 泛化形式是n\*m的矩阵和n\*1或1\*m的矩阵相加。在执行加法操作时，其实是将n\*1或1\*m矩阵复制成为n\*m的矩阵，然后两者做逐元素加法得到结果。
<br>

* 广播机制的通用形式
	* &emsp;  一个m\*n矩阵 加/减/乘/除 一个 n\*1或1\*m的单行或列矩阵，这个行或列矩阵n\*1或1\*m矩阵都会复制自身成为m\*n矩阵，然后才与那个m\*n矩阵逐元素 加/减/乘/除
	* &emsp;  此通用形式不仅对单行或列矩阵有效，对实数也有同样效果，实数与m\*n矩阵四则运算前也会自身先扩展成一个m\*n矩阵再与这个矩阵逐元素运算。
	* &emsp;  单行或列矩阵与实数四则运算，实数也执行广播机制再逐元素运算,同样地，两个单行和单列矩阵之间的运算也适用。

<br>

### 2.16 关于 Python 与numpy 向量的使用（A note on python or numpy vectors）
* python广播的优缺点
	* 优点：灵活，一行代码就能完成很多功能。
	* 缺点：必须熟悉广播机制，否则容易产生意外的结果，但程序又不会报错。

* python-numpy的一些使用细节
	* &emsp;  a=np.random.randn(5)，这样会生成存储在数组a 中的5 个高斯随机数变量。打印a时，a的形式跟一个行向量格式一样，但在python里，这是一个一维数组，不是行向量。
	* &emsp;  **注意：** 向量和数组的区别，数组是编程概念，一种数据结构，与单向量格式非常相似，用作暂时保存一系列数据，但对数组进行科学计算时，结果会和向量的不一样，所以在逻辑回归和神经网络需要矩阵运算时，必须确保是用行/列向量计算而不是数组。
	<br>
	* 如何区分向量和数组
		* &emsp; 刚刚代码a=np.random.randn(5)生成的数组，其数据结构(a.shape)是(5,);而行向量的数据结构(行向量.shape)应该是(1,5);列向量的数据结构(行向量.shape)应该是(5,1)
		* 一个细微的差别，在这种数据结构中，当我们输出a的转置时有两对方括号，而之前只有一对方括号，所以这就是1行5列的矩阵和一维数组的差别。
	 &emsp;一维数组：[ 1.  1.  1. -1.  0.]
	 &emsp;单行矩阵：\[[-1. -1. -1.  2. -0.]]


* 断言语句(assertion statement)
	&emsp;用python的断言语法，检查数据结构是数组还是矩阵：
	$$assert(a.shape==(5,1))$$
	
* &emsp;另外，为了确保你的矩阵或向量所需要的维数时，不要羞于重塑矩阵reshape操作。	
	$$cal=A.reshape(5,1)$$

	
	
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTM2OTkxMzM0MF19
-->