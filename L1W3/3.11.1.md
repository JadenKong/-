### 3.11 随机初始化（ 随机初始化（ 随机初始化（ 随机初始化（ 随机初始化（ 随机初始化（ Random+Initialization）
* 假设神经网络有两个输入特征， 即 $n^{[0]}$等于 2，2个隐藏层单元 n[1]就等于 2。因 此与一个隐藏层相关的矩阵W[1]是 2\*2的矩阵， 假设把它初始化为 0的 2*2矩阵， b[1]也等于 [0 0]^T，把偏置项 b初始化为 0是合理的，但是把 w初始化为0就有问题了。
* 假设W[1]是全0矩阵
	* 那么隐藏层的神经单元$a_1^{[1]},a_2^{[1]}$将会完全一样，他们的激活函数也将完全一样。（这里我理解是，就算使用的函数不一样，譬如a_1用tanh,a_2用relu,由于W矩阵是全0作用在X矩阵的结果就是全0，所以用什么函数都是一样结果。）
	* 由于$a_1^{[1]}=a_2^{[1]}$，所以$dz_1^{[1]}=dz_2^{[1]}$，继而得出，dW1矩阵，上下两行元素（即第一个和第二神经单元的w值）是完全相等的。
	* 根据梯度下降公式，每次更新
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTEwOTE3Nzk3NV19
-->